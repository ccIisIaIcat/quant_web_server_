在k_line_demo和mul_modle_demo中发现：
    1、实时订单报价更新速率快，样本数据维度高
    2、多样本实时监控存在明显的即时性差，数据迟滞等问题

为进一步推进工程，现希望实现以下功能：
    1、输入symbol，自动在mysql对应symbol数据库中建立一个以开始时间为题目的数据库
    2、开始同时收集多维度的，以时间为标度的数据，具体而言，要求有：
        1：归集交易数据 {
            "e": "aggTrade",  // 事件类型
            "E": 123456789,   // 事件时间
            "s": "BNBUSDT",    // 交易对
            "a": 5933014,     // 归集成交 ID
            "p": "0.001",     // 成交价格
            "q": "100",       // 成交量
            "f": 100,         // 被归集的首个交易ID
            "l": 105,         // 被归集的末次交易ID
            "T": 123456785,   // 成交时间
            "m": true         // 买方是否是做市方。如true，则此次成交是一个主动卖出单，否则是一个主动买入单。
            }
        2：最新标记价格 {
            "e": "markPriceUpdate",     // 事件类型
            "E": 1562305380000,         // 事件时间
            "s": "BTCUSDT",             // 交易对
            "p": "11794.15000000",      // 标记价格
            "i": "11784.62659091",      // 现货指数价格
            "P": "11784.25641265",      // 预估结算价,仅在结算前最后一小时有参考价值
            "r": "0.00038167",          // 资金费率
            "T": 1562306400000          // 下次资金时间
        }
        3：最优挂单信息 {
            "e":"bookTicker",     // 事件类型
            "u":400900217,        // 更新ID
            "E": 1568014460893,   // 事件推送时间
            "T": 1568014460891,   // 撮合时间
            "s":"BNBUSDT",        // 交易对
            "b":"25.35190000",    // 买单最优挂单价格
            "B":"31.21000000",    // 买单最优挂单数量
            "a":"25.36520000",    // 卖单最优挂单价格
            "A":"40.66000000"     // 卖单最优挂单数量
            }
        4：有限档深度信息 {
            "e": "depthUpdate",           // 事件类型
            "E": 1571889248277,           // 事件时间
            "T": 1571889248276,           // 交易时间
            "s": "BTCUSDT",
            "U": 390497796,
            "u": 390497878,
            "pu": 390497794,
            "b": [                        // 买方
                [
                "7403.89",                // 价格
                "0.002"                   // 数量
                ]
            ],
            "a": [                        // 卖方
                [
                "7405.96",                // 价格
                "3.340"                   // 数量
                ]
            ]
            }
        5：增量深度信息 {
            {
            "e": "depthUpdate",   // 事件类型
            "E": 123456789,       // 事件时间
            "T": 123456788,       // 撮合时间
            "s": "BNBUSDT",       // 交易对
            "U": 157,             // 从上次推送至今新增的第一个 update Id
            "u": 160,             // 从上次推送至今新增的最后一个 update Id
            "pu": 149,            // 上次推送的最后一个update Id(即上条消息的‘u’)
            "b": [                // 变动的买单深度
                [
                "0.0024",         // 价格
                "10"              // 数量
                ]
            ],
            "a": [                // 变动的卖单深度
                [
                "0.0026",         // 价格
                "100"             // 数量
                ]
            ]
            }
        }
    3、在本地维护一个orderbook时间序列{
        如何正确在本地维护一个orderbook副本：
        a.订阅 wss://fstream.binance.com/stream?streams=btcusdt@depth
        b.开始缓存收到的更新。同一个价位，后收到的更新覆盖前面的。
        c.访问Rest接口 https://fapi.binance.com/fapi/v1/depth?symbol=BTCUSDT&limit=1000获得一个1000档的深度快照
        d.将目前缓存到的信息中u< 步骤3中获取到的快照中的lastUpdateId的部分丢弃(丢弃更早的信息，已经过期)。
        e.将深度快照中的内容更新到本地orderbook副本中，并从websocket接收到的第一个U <= lastUpdateId 且 u >= lastUpdateId 的event开始继续更新本地副本。
        f.每一个新event的pu应该等于上一个event的u，否则可能出现了丢包，请从step3重新进行初始化。
        g.每一个event中的挂单量代表这个价格目前的挂单量绝对值，而不是相对变化。
        h.如果某个价格对应的挂单量为0，表示该价位的挂单已经撤单或者被吃，应该移除这个价位。
    }

    具体实现和其他
    1、考虑到一共需由五个线程开启同时进行的五个任务，考虑在database中同时开辟五个table分别保存数据
    2、考虑数据传递速率高，mysql数据接收为单次一百条，且暂时以byte形式存储（blob），减少中间处理流程
    3、关于websocket如有心跳问题后续处理

    具体实现：可从单一symbol的单一维度收集一次十五分钟以上的数据（用于考察ping pong问题），录入mysql
            进而尝试二维数据的多线程操作（用于考察mysql同步录入的问题），顺便考察blob长度是否充足
                在录入全部完成后，建立一个新的，以时间为升序依据的合并列表，同时建立一个本地的orderbook

    实现完成后，可通过进一步的数据分析，考察不同时间维度的数据的关系